# Fallstudie - â€Wie hoch ist die mediane Lieferzeit"

Diese Fallstudie zeigt Dir Schritt fÃ¼r Schritt, wie du eine scheinbar harmlose Frage (â€Wie hoch ist die mediane Lieferzeit?") vollstÃ¤ndig analysierst â€“ genauso wie in deiner Capstone-Abgabe.

Der Median ist nicht trivial:
Er hÃ¤ngt von Frequenz, Latenz, Population, Slice, Datenmodell, Workload und Query Paths ab.

Du lernst hier:

- wie du Datenarten sauber identifizierst (Modul 1)
- wie du Workloads quantifizierst (Modul 2)
- wie du DB-Engines auswÃ¤hlst (Modul 3)
- wie du Query Paths analysierst (Modul 4)

Am Ende steht ein voll durchargumentiertes Beispiel, das du als Strukturgrundlage fÃ¼r dein Capstone verwenden kannst.

---

## MODUL 1 â€” Datenarten | Zugriffsmuster | Zugriffsszenarien

Wir arbeiten strikt entlang der Checkliste.

### âœ” Modul-1-Checkliste: â€Alle Datenarten korrekt identifiziert"

FÃ¼r die Frage â€Wie hoch ist die mediane Lieferzeit?" benÃ¶tigen wir folgende Datenobjekte:

**Objekt A â€” Bestellung:**

- Datenart: strukturiert
- Felder: order_id, customer_id, product_id, order_date, shipping_date, delivery_date
- Warum? Der Median entsteht aus vielen einzelnen Lieferzeiten.

**Objekt B â€” Lieferzeit (berechnetes Feld):**

- Datenart: ephemeral (berechnet, nicht persistent)
- Warum? delivery_date â€“ order_date wird bei jeder Berechnung neu erzeugt.

**Objekt C â€” Aggregierte Statistik (Median-Wert):**

- Datenart: kleines persistentes Objekt
- Warum? Optional persistent, wenn Memoization oder Materialized View genutzt wird.

**Objekt D â€” Filter/Slice-Parameter:**

- Datenart: kleines JSON / Parameterobjekt
- Warum? Median variiert je Produkt, Lieferant, Region usw.

### âœ” Modul-1-Checkliste: â€Zu jedem Objekt das passende Zugriffsmuster festgelegt"

| Objekt | Zugriffsmuster | Warum? |
|--------|----------------|--------|
| Bestellung | Read/Write mixed | es gibt neue Orders + Korrekturen |
| Lieferzeit | read-heavy bulk | wird bei Median-Abfrage Ã¼ber viele Zeilen berechnet |
| Median-Wert | read-heavy, selten write | lesen oft, aktualisieren selten |
| Slice-Parameter | read-only | wird nur als Filter genutzt |

### âœ” Modul-1-Checkliste: â€FÃ¼r jedes Objekt ein Zugriffsszenario formuliert"

**Objekt A â€” Bestellung**
â€Lese alle Bestellungen (ggf. per Slice) und extrahiere order_date & delivery_date."

**Objekt B â€” Lieferzeit**
â€Berechne fÃ¼r jede Bestellung die Lieferzeit (delivery_date âˆ’ order_date)."

**Objekt C â€” Median-Wert**
â€Lese die voraggregierte Statistik aus MV oder Tabelle."

**Objekt D â€” Slice-Parameter**
â€Wende Filter (WHERE product_id=â€¦ / region=â€¦) an."

### âœ” Modul-1-Checkliste: â€Saubere Trennung (Dokument/Vektor etc.)"

- Keine Vektoren â†’ irrelevant
- Kein Ephemeral-State auÃŸer der Lieferzeit â†’ sauber getrennt
- Bestellung persistent, Lieferzeit ephemeral
- Median persistent (bei Precompute)

---

## ğŸŸ  MODUL 2 â€” Workloads definieren

Jetzt wird jeder Punkt der Checkliste abgearbeitet.

### âœ” Modul-2-Checkliste: â€FÃ¼r jedes Objekt ein Zugriffsszenario aus Modul 1"

Dies haben wir oben â€” wir Ã¼bernehmen sie unverÃ¤ndert als Basis.

### âœ” Modul-2-Checkliste: â€Aus jedem Szenario einen Workload mit konkreten Zahlen ableiten"

Wir definieren realistische Mengen:

**Systemdaten:**

- 12.000 Bestellungen pro Tag
- Median-Abfrage: 300 Anfragen / Stunde
- Peak: 600 Median-Abfragen / Stunde

**Workloads je Objekt:**

**Objekt A â€“ Bestellung:**

- Reads/s: ~3.3
- Writes/s: ~0.1
- ParallelitÃ¤t: mittel
- KritikalitÃ¤t: hoch (Konsistenz!)

**Objekt B â€“ Lieferzeit (berechnet):** pro Median-Abfrage:

- 12.000 Bestellungen lesen
- 12.000 Lieferzeiten berechnen

Workload:

- 300 Abfragen/h â†’ jede ~12000 rows
- 300 * 12.000 = 3.6 Mio Berechnungen pro Stunde
- Peak: 7.2 Mio/h

â†’ eindeutig scan-heavy + sort-heavy

**Objekt C â€“ Median-Wert:**

- Reads: 300/h
- Writes: 1 alle 5 Minuten

â†’ read-heavy

**Objekt D â€“ Slice-Parameter:** vernachlÃ¤ssigbar

### âœ” Modul-2-Checkliste: â€BegrÃ¼nden, welche Messwerte du brauchst"

Notwendige Messwerte:

- Cost of full table scan (Zeit pro 10k, 100k Zeilen)
- Cost of sort operation
- Latency for WHERE-Slices (pro product_id, supplier_id etc.)
- MV-refresh-Latenz
- Concurrent median calculations

Ohne diese Kennzahlen ist keine Engine-Wahl mÃ¶glich.

### âœ” Modul-2-Checkliste: â€Zeigen, dass deine Entscheidung auf Zahlen basiert"

â†’ wir vergleichen spÃ¤ter mit konkreten Postgres-Messwerten
(z. B. 5â€“20 ms pro 10k Zeilen via Index, 50â€“80 ms fÃ¼r sortierten Slice).

---

## ğŸŸ¡ MODUL 3 â€” DB-Auswahl anhand der sechs Profi-Kriterien

Jetzt arbeiten wir alle Checklistenpunkte ab.

### âœ” Modul-3-Checkliste: â€Datenobjekte definieren"

â†’ bereits in Modul 1 sauber erledigt.

### âœ” Modul-3-Checkliste: â€Zugriffsszenarien bestimmen"

â†’ bereits definiert:

- Bulk-Scan
- Slice-Sort
- MV-Read
- MV-Refresh

### âœ” Modul-3-Checkliste: â€Workloads quantifizieren"

â†’ haben wir in Modul 2 mit konkreten Zahlen getan (3.6 Mio Berechnungen/h).

### âœ” Modul-3-Checkliste: â€Messwerte anwenden"

Beispielhafte realistische Werte (Postgres):

- Full Table Scan 12.000 rows: 6â€“12 ms
- Sort 12.000 numeric values: 5â€“8 ms
- MV-Read: <2 ms
- MV-refresh: 20â€“40 ms (async)

Mongo-typische Werte:

- Sort Ã¼ber 12.000 Dokumente: 40â€“120 ms
- Scan via Aggregation: 20â€“60 ms

â†’ riskant

Redis:

- keine Sortierabfragen â†’ ungeeignet

### âœ” Modul-3-Checkliste: â€Die sechs Kriterien nutzen"

**Kriterium 1 â€” Konsistenz**
Bestellungen brauchen ACID
â†’ Postgres Pflicht

**Kriterium 2 â€” Workload-Form**
Scan-heavy, sort-heavy
â†’ Postgres stark
â†’ Mongo schwach

**Kriterium 3 â€” Lastprofil**
300 Median-Abfragen/h
â†’ Sort pro Anfrage? â†’ zu teuer
â†’ MV oder Precompute nÃ¶tig

**Kriterium 4 â€” Kritische Query Paths**
Median liegt im CRITICAL PATH â†’ muss optimiert werden.

**Kriterium 5 â€” Modellrisiko**
Mongo Aggregation-Framework ineffizient bei Sort
â†’ groÃŸes Risiko

**Kriterium 6 â€” Operability**
Postgres: MV, Indexing, ACID â†’ stabil
Mongo: keine MV
Redis: ungeeignet

### âœ” Modul-3-Checkliste: â€Alternativen ausschlieÃŸen"

- MongoDB: teuer bei sort-heavy + kein MV â†’ ausgeschlossen
- Redis: ungeeignet fÃ¼r Sort â†’ ausgeschlossen
- Elasticsearch: teuer fÃ¼r median aggregation â†’ oversized

### âœ” Modul-3-Checkliste: â€Finale Entscheidung begrÃ¼nden"

**Gewinner: Postgres** mit:

- einer Tabelle â€orders"
- einer MV â€delivery_times"
- Index auf product_id, region
- regelmÃ¤ÃŸiger MV-Refresh

---

## ğŸŸ¢ MODUL 4 â€” Query Paths bestimmen, kritische Pfade markieren

Auch hier arbeiten wir die Checkliste streng ab.

### âœ” Modul-4-Checkliste: â€Welche Query Paths hat dein System?"

**Path A â€” Median â€on demandâ€œ (schlechte Variante):**

1. Read orders (12.000 rows)
2. Berechne Lieferzeit
3. Sortiere alle Werte
4. Berechne Median
5. Antwort zurÃ¼ck

â†’ teuer, blockierend, schlecht skalierbar

**Path B â€” Median Ã¼ber Materialized View (professionelle Variante):**

1. MV lesen (indexiert, klein)
2. minimaler Sort
3. Median lesen

â†’ VERY LOW LATENCY (<20 ms)

**Path C â€” MV-Refresh (asynchron):**

1. scan new orders
2. berechne Lieferzeiten
3. update MV

â†’ nicht kritisch

### âœ” Modul-4-Checkliste: â€Welche davon sind kritisch?"

**Kritisch:**

- Path B (Median lesen)

**Nicht kritisch:**

- Path C (MV refresh)
- Bestellungs-Write
- Logging

### âœ” Modul-4-Checkliste: â€Welche Datenbanken sind involviert?"

- Postgres (orders + MV)
- keine weiteren Systeme

### âœ” Modul-4-Checkliste: â€Welche Latenzanforderungen gelten?"

- Median-Abfrage: < 80 ms (akzeptabel)
- Ziel: < 20 ms (optimal)
- MV-refresh: egal (asynchron)

### âœ” Modul-4-Checkliste: â€Warum ist dein Modell fÃ¼r diese Paths optimiert?"

Weil:

- MV entlastet critical path
- Indexe reduzieren Sortierkosten
- Postgres kann numeric sorts effizient durchfÃ¼hren
- bulk-scan findet im background statt
- Orders bleiben ACID
- Roundtrips minimal (1 Query gegen MV)

### âœ” Modul-4-Bewertungskriterien erfÃ¼llt

- kritische Pfade korrekt erkannt â†’ JA
- Modell optimiert kritische Pfade â†’ JA
- Roundtrips vermieden â†’ JA
- DB-Wahl unterstÃ¼tzt Query-Pfad â†’ JA

---

## ğŸ“¦ ENDGÃœLTIGES ERGEBNIS

Wenn du diese Fallstudie nachbaust, brauchst du nur die Objektbezeichnungen austauschen â€” Struktur und Argumentationslogik bleiben identisch.

Dieses Beispiel zeigt dir:

- wie du sauber argumentierst
- wie du deine Checklisten abarbeitest
- wie Profi-Architektur dokumentiert wird
- wie du Fehler vermeidest (Mongo fÃ¼r Sorts!)
