# MusterlÃ¶sung

MusterlÃ¶sung â€“ E-Commerce RAG System: KONKRETE Definition des Szenarios
Bitte kopieren:

## ğŸ“¦ Fiktives E-Commerce-Szenario (klar definiert)

Ihr baut ein RAG-System fÃ¼r den Kundensupport eines mittelgroÃŸen Online-HÃ¤ndlers:

### Produkte (Katalog)

- Elektronik (Smartphones, Laptops, KopfhÃ¶rer)
- HaushaltsgerÃ¤te (Staubsauger, Kaffeemaschinen)
- Kleidung (Jacken, Schuhe)

Sortiment: 8.500 Produkte

### Daten, die existieren

- Produktbeschreibungen (HTML â†’ Text)
- Produktattribute (Preis, GrÃ¶ÃŸe, Gewicht, Garantie)
- Betriebsanleitungen (PDF â†’ Text â†’ Chunks)
- Retourenrichtlinien (Text)
- Kundenkonten (SQL)
- Bestellungen und Zahlungen (SQL)
- Supporttickets (JSON)
- ChatverlÃ¤ufe mit Kunden (JSON, append-only)

### Was der Support leisten kann

- "Wo ist mein Paket?"
- RÃ¼ckgabe/Retoure erklÃ¤ren
- Technische Produktfragen (z. B. â€Wie entkalke ich XY?")
- Fehlerdiagnose (â€Meine Kaffeemaschine blinkt gelbâ€¦")
- Preisinformationen
- Garantie- und Seriennummernfragen
- Produktvergleiche (â€Welches Headset ist leiser?")

### Lastszenario (realistisch, nicht akademisch)

- 120 Supportmitarbeiter weltweit
- Jeder bearbeitet ~2 Chats gleichzeitig
- 70 Kund*innen gleichzeitig im Chat
- Durchschnitt: 1 RAG-Query pro 6 Sekunden pro aktivem Chat

â†’ ~12 RAG-Queries pro Sekunde im Gesamtsystem

**Jeder RAG-Request benÃ¶tigt:**

1. Rate Limit prÃ¼fen (Redis)
2. Session Context laden (Redis/Mongo)
3. Query-Preprocessing (kein DB-Zugriff)
4. Vektor-Search auf Chunks (pgvector)
5. Dokumente nachladen (Mongo/JSONB)
6. Produktmetadaten prÃ¼fen (PG)
7. Berechtigungen prÃ¼fen (PG)
8. Antwort-Komponenten cachen (Redis)
9. Logging (Timescale/PG)

â†’ pro Anfrage 8â€“12 DB-Operationen

## Ok, und was bedeutet es in der Praxis 8-12 DB Operationen zu haben?

Modellierung des E-Commerce-Support-RAG-Systems (konkreter Flow)

**Ziel dieses Abschnitts:** Ihr seht an einem ganz konkreten Beispiel, wie viele Einzelschritte ein einziger Support-Request tatsÃ¤chlich hat â€“ und warum dabei mehrere Datenbanken beteiligt sind.

## ğŸ§© Ausgangspunkt: Ein konkreter Support-Use-Case

Ein Kunde schreibt in den Chat:

â€Meine Kaffeemaschine Modell X blinkt gelb, was soll ich tun?"

Der Support-Agent arbeitet in einem internen Web-Tool, das im Hintergrund ein RAG-System nutzt.

Das System soll:

1. PrÃ¼fen, ob der Request zulÃ¤ssig ist (Rate-Limits, Missbrauch).
2. Den aktuellen Chat-Kontext kennen (vorherige Nachrichten im Verlauf).
3. Relevante Dokumentstellen finden (Produktbeschreibung, Anleitung, Troubleshooting-Artikel).
4. PrÃ¼fen, ob der Support-Agent fÃ¼r diesen Kunden / diese Daten berechtigt ist.
5. Die Antwort des LLM loggen (fÃ¼r Monitoring und Audit).

Daraus ergibt sich ein konkreter Request-Flow.

## ğŸ” Schritt-fÃ¼r-Schritt-Flow eines einzelnen RAG-Requests

Wir gehen bewusst granular vor â€“ das ist das Modell, auf dem spÃ¤ter die 8 Fragen aufbauen.

## 0. HTTP-Request trifft beim Backend ein

Eingehende Anfrage: POST /support/rag-answer

EnthÃ¤lt: Session-Token, User-ID, Agent-ID, Frage-Text, evtl. Produkt-ID.

Noch kein Datenbankzugriff.

## 1. Rate-Limit prÃ¼fen (Redis INCR + EXPIRE)

**Warum Ã¼berhaupt Rate-Limits?**

- Schutz vor Bots / Abuse / Fehlkonfigurationen
- Kostenkontrolle bei LLM-Calls
- StabilitÃ¤t des Systems

**Typisches Pattern:**

Key: "ratelimit:{user_id}:{minute}"

- INCR key â†’ ZÃ¤hlt, wie viele Requests in diesem Zeitfenster schon kamen.
- EXPIRE key, 60 â†’ Nach 60 Sekunden ist der ZÃ¤hler weg.

**Konkrete DB-Operationen:**

- INCR ratelimit:12345:2025-11-24T10:15
- EXPIRE ratelimit:12345:2025-11-24T10:15, 60

Wenn INCR z. B. > 30 ist â†’ Request wird abgelehnt.

ğŸ‘‰ Das ist der â€Redis INCR" aus den spÃ¤teren Antworten.

## 2. Session-Kontext laden (Redis GET / ggf. HGETALL)

**Warum Session-Kontext?**

- Damit das LLM den bisherigen GesprÃ¤chsverlauf kennt (â€Ich hatte doch vorhin schon gefragtâ€¦").
- Um z. B. SprachprÃ¤ferenzen, gewÃ¤hlte Produktkategorie, Kunde vs. Gast zu kennen.

**Typischer Key:** "session:{session_id}"

**Wert:** kleines JSON mit den letzten N Nachrichten oder Referenzen darauf.

**DB-Operation:**

GET session:abc123

Wenn Session nicht vorhanden â†’ neue Session anlegen.

ğŸ‘‰ Das ist der â€Session auslesen"-Teil in den Antworten.

## 3. Query zu Embedding machen & Vektor-Suche (pgvector)

Der Text â€Meine Kaffeemaschine X blinkt gelbâ€¦" wird in einen Embedding-Vektor umgerechnet (in der Applikation, nicht in der DB).

Dann:

**pgvector-Query:**

```sql
SELECT doc_id, chunk_id, 1 - (embedding <=> $query_vec) AS score
FROM chunks
WHERE product_family = 'Kaffeemaschine'
ORDER BY embedding <-> $query_vec
LIMIT 8;
```

1 ANN/Vector-Query pro RAG-Request

Ergebnis: Liste von Chunk-IDs mit Scores

ğŸ‘‰ Das ist der â€pgvector ANN-Search" aus den Antworten.

## 4. Original-Chunks nachladen (Mongo oder PG JSONB)

Die Chunks, auf die doc_id + chunk_id verweisen, werden jetzt geladen:

**Beispiel Mongo-Dokument:**

```json
{
  "_id": "...",
  "doc_id": "manual_X_de",
  "chunk_id": 42,
  "text": "Wenn die gelbe LED blinkt, entkalken Sie das GerÃ¤t wie folgt...",
  "product_id": "KM-1234",
  "tags": ["troubleshooting", "entkalken"]
}
```

Ãœblicherweise:

- 3â€“8 Chunk-Dokumente pro RAG-Request
- 1â€“2 Mongo-Queries (mit $in auf chunk_id)

ğŸ‘‰ Das sind die â€Chunk-Fetches" aus den Antworten.

## 5. Produkt-Metadaten & Berechtigungen in Postgres prÃ¼fen

**Metadaten:**

- Produkt existiert?
- Produkt noch im Sortiment?
- Regionale Unterschiede? (EU vs. US-Version)

**SQL-Beispiel:**

```sql
SELECT p.id, p.name, p.region, p.obsolete
FROM products p
WHERE p.id = $product_id;
```

**Berechtigungen (RBAC):**

- Darf dieser Agent dieses Ticket sehen?
- GehÃ¶rt der Kunde zu dieser Region?
- Darf diese Information (z. B. Garantiedetails) angezeigt werden?

**SQL-Beispiel:**

```sql
SELECT 1
FROM agent_permissions ap
JOIN customers c ON c.region = ap.region
WHERE ap.agent_id = $agent_id
  AND c.id = $customer_id;
```

ğŸ‘‰ Das ist der Teil â€Produktmetadaten + BerechtigungsprÃ¼fung in Postgres".

## 6. Antwort generieren & kurzzeitig cachen (Redis SETEX)

Das LLM produziert eine Antwort. Um Folgerequests schneller zu machen (z. B. bei â€Kannst du das anders formulieren?"), kann man die Antwort oder die Retrieval-Resultate im Cache ablegen.

**Beispiel:**

- Key: "ragcache:{session_id}:{hash(user_question)}"
- Wert: Antworttext + verwendete Chunks
- TTL: z. B. 120 Sekunden

**DB-Operation:**

SETEX ragcache:abc123:xyz 120 {json-payload}

ğŸ‘‰ Das ist das â€SETEX/Caching", von dem spÃ¤ter die Rede ist.

## 7. Chat-History fortschreiben (Mongo)

Die neue Nachricht des Agenten wird dem Chat-Verlauf hinzugefÃ¼gt:

```json
{
  "session_id": "abc123",
  "customer_id": "C987",
  "messages": [
    { "from": "customer", "ts": "...", "text": "..." },
    { "from": "agent", "ts": "...", "text": "..." }
  ]
}
```

Je nach Modellierung:

- Ein updateOne mit $push auf messages
- Oder EinfÃ¼gen eines neuen Message-Dokuments

ğŸ‘‰ Das ist der â€Chat-Append"-Teil in Mongo.

## 8. Logging / Monitoring (Timescale / PG)

FÃ¼r Monitoring & Auditing wird ein Logeintrag geschrieben:

- Timestamp
- Agent-ID
- Kunden-ID
- Antwortdauer (ms)
- Anzahl der verwendeten Chunks
- Fehler? (ja/nein)

**Beispiel Timescale-Insert:**

```sql
INSERT INTO support_logs (ts, agent_id, customer_id, latency_ms, chunks_used, error)
VALUES (now(), $agent, $customer, $latency, $chunks, false);
```

ğŸ‘‰ Das ist das â€Timescale INSERT â†’ Log".

## ğŸ“Œ Zusammenfassung des Ein-Request-Flows in DB-Operationen

FÃ¼r eine einzige Frage des Kunden:

1. Redis: INCR + EXPIRE
2. Redis: GET (Session)
3. pgvector: 1 ANN-Query
4. Mongo: 1â€“2 Queries (3â€“8 Chunks)
5. Postgres: 1â€“2 Queries (Metadaten + Permission)
6. Redis: SETEX (Cache)
7. Mongo: updateOne oder insertOne (Chat)
8. Timescale: INSERT (Log)

â†’ 8â€“14 DB-Operationen pro RAG-Request, je nach Details.

Das ist exakt die Basis, auf der spÃ¤ter die Musterantworten zu Frage 2 (â€Wie viele DB-Operationenâ€¦") aufbauen.

## ğŸ”· Abschnitt: Von RAG-Requests/s zu DB-Ops/s â€“ warum das TROTZ 10k writes/s relevant ist

**Ziel dieses Abschnitts:** Ihr versteht, warum â€210 DB-Operations pro Sekunde" nicht einfach bedeutungslos sind, obwohl ihr lokal 10.000 Inserts/s gemessen habt.

### 1ï¸âƒ£ Unterschied: Microbenchmark vs. echter Request-Mix

**Eure Benchmarks:**

- 10.000 Inserts in Mongo mit insert_many â†’ sehr schnell
- 10.000 Inserts in Postgres in einer Transaktion â†’ auch ordentlich
- 10.000 Redis-SETs per Pipeline â†’ ebenfalls sehr schnell

**Aber:**

Das waren jeweils optimierte Bulk-Szenarien:

- Ein Datentyp
- Eine Operation
- Keine parallelen User
- Kein Netzwerk
- Keine zusÃ¤tzlichen Indizes
- Keine Permission-Checks
- Kein Logging
- Kein LLM im Loop

Im echten System ist jeder Request ein bunter Mix aus:

- leichten Operationen (INCR, GET)
- mittelschweren Operationen (Mongo-Reads, einfache SELECTs)
- teuren Operationen (ANN-Search, Joins)

### 2ï¸âƒ£ DB-Operationen sind nicht gleich â€Kostenlos"

Ihr habt oben gesehen:

- Ein Redis INCR ~ Mikrosekunden-Bereich
- Eine pgvector-ANN-Query ~ mehrere Millisekunden (abhÃ¤ngig von Index, Dimension usw.)
- Ein Mongo-Read mit kalten Daten â†’ 10â€“50ms
- Ein Postgres-Join unter Last â†’ 5â€“20ms

Wenn ihr jetzt sagt:
â€Wir haben 15 RAG/s und damit 120â€“210 DB-Ops/s"
ist die entscheidende Frage:

**Wie viele davon sind â€billige" Ops und wie viele â€teure"?**

Denn ein System mit:

- 200 Ã— INCR/s (Redis) ist langweilig
- 200 Ã— ANN-Search/s (pgvector) ist ernstzunehmende Last

### 3ï¸âƒ£ Kritischer Pfad vs. Luxus-Pfad

Nicht jede Operation ist gleich kritisch.

- Wenn das Logging 1 Sekunde spÃ¤ter geschrieben wird â†’ nicht so schlimm.
- Wenn das Rate-Limit 500ms braucht â†’ Chat wirkt kaputt.
- Wenn ANN-Search manchmal 300ms statt 40ms dauert â†’ der ganze Dialog wirkt trÃ¤ge.

**Deshalb:**

Wir zÃ¤hlen Ops/s nicht nur als â€Menge",

sondern fragen: Welche liegen im kritischen Pfad fÃ¼r die User Experience?

### 4ï¸âƒ£ ParallelitÃ¤t und Skalierung

Lokal habt ihr getestet: ein Prozess, eine DB, keine echte ParallelitÃ¤t mit 100 Usern.

Im echten System:

- mehrere gleichzeitige Requests
- Threads / Worker / Container
- mehrere Datenbanken
- Netzwerk-Hops zwischen Services

â†’ Die effektive KapazitÃ¤t pro DB hÃ¤ngt davon ab, wie gut sie parallel arbeiten kann, ob sie CPU-bound oder IO-bound wird, und ob ihr Spitzenlast abfangen kÃ¶nnt.

### 5ï¸âƒ£ Warum die Zahl 120â€“210 DB-Ops/s trotzdem Gold wert ist

Sie ist der Startpunkt fÃ¼r:

- Dimensionierung (Wie viele Instanzen/Container?)
- Risikobewertung (Wo knallt es zuerst?)
- Architekturauswahl (â€Kann ich Rate-Limits wirklich in Postgres machen? â†’ Nein.")
- Priorisierung (Was optimiere ich zuerst? ANN-Index, Redis, Mongo?)

Ohne diese GrÃ¶ÃŸenordnung bleibt alles gefÃ¼hlt:

â€Mongo ist doch schnell genugâ€¦ auf meinem Laptop."

Mit dieser GrÃ¶ÃŸenordnung kÃ¶nnt ihr gezielt argumentieren:

â€Rate-Limits gehÃ¶ren in Redis, weil 15 RAG/s Ã— 2 Redis-Calls Ã— 5er Sicherheitsfaktor â†’ 150 ops/s. Das ist trivial fÃ¼r Redis, aber fÃ¼r Postgres wÃ¤ren das 150 zusÃ¤tzliche Sync-Writes/s im kritischen Pfad â€“ unnÃ¶tig teuer und fehleranfÃ¤llig."

## ğŸŸ¦ TEIL 1 â€“ MusterlÃ¶sung zu den 8 Last-/Scaling-Fragen

Zu jeder Frage bekommt ihr:

- schlechte Antwort (falsch oder unprÃ¤zise)
- gute Antwort (korrekt)
- exzellente Antwort (technisch prÃ¤zise + begrÃ¼ndet + numerisch)

## 1. Wie viele RAG-Requests pro Sekunde erwartet ihr?

**Schlecht:**
â€Kommt drauf an, aber bestimmt nicht viele."

**Gut:**
â€12 Requests pro Sekunde, ausgehend von 70 parallelen Chats und einer Anfrage alle 6 Sekunden."

**Exzellent:**
â€Bei 70 parallelen Chats Ã— 1 RAG-Query alle 6s entstehen ~12 Queries pro Sekunde (70/6 â‰ˆ 11.7). Dazu kommen 2â€“3 weitere Queries pro Sekunde durch Parallelaktionen wie Ticketupdates. Wir rechnen mit 15 RAG-Requests pro Sekunde unter Normalbetrieb und bis zu 40 unter Lastspitzen (Sale-Events, Black Friday)."

## 2. Wie viele DB-Operationen verursacht EIN einzelner RAG-Request?

**Schlecht:**
â€Nur eine fÃ¼r die Vektor-Suche."

**Gut:**
â€8â€“10 DB-Operationen, weil mehrere Systeme beteiligt sind."

**Exzellent:**
â€In diesem Use-Case erzeugt ein RAG-Request:

- Redis INCR â†’ Rate-Limit
- Redis GET â†’ Session Context
- PG/pgvector â†’ ANN-Search
- Mongo â†’ 3â€“5 Chunk-Fetches
- PG â†’ Produktmetadaten
- PG â†’ BerechtigungsprÃ¼fung
- Redis SETEX â†’ Cache
- Timescale INSERT â†’ Log

= 8â€“14 DB-Operationen pro RAG-Request
Bei 15 RAG/s â†’ 120â€“210 DB-ops/s."

## 3. Welche DB wird am stÃ¤rksten belastet? Warum?

**Schlecht:**
â€Die Vektor-DB, weil die wichtig ist."

**Gut:**
â€Redis, weil Rate-Limits und Sessions jede Anfrage betreffen."

**Exzellent:**
â€Redis wird am stÃ¤rksten belastet (~30â€“60 ops/s), da jede Anfrage:

- Rate-Limit aktualisiert
- Session ausliest
- Cache invalidiert oder beschreibt

pgvector ist zweiter (10â€“20 ops/s), aber mit teureren Einzeloperationen.
Mongo wird je nach Chunking 20â€“40 ops/s sehen (mehrere kleine Reads)."

## 4. Welche DB ist Single Point of Failure?

**Schlecht:**
â€Eigentlich keine, wir kÃ¶nnen ja replizieren."

**Gut:**
â€Redis ist kritisch, weil Rate-Limiting und Sessions dort liegen."

**Exzellent:**
â€Redis ist operational der kritischste Pfad, weil ohne Rate-Limits der Schutz vor Spam-Bots entfÃ¤llt und ohne Session-State die gesamte Chat-KohÃ¤renz bricht. pgvector ist kritisch fÃ¼r die AntwortqualitÃ¤t, aber Redis ist kritisch fÃ¼r SystemstabilitÃ¤t."

## 5. Welche DB braucht horizontales Scaling?

**Schlecht:**
â€pgvector, weil Machine Learning."

**Gut:**
â€Mongo, weil es viele Reads bekommt."

**Exzellent:**
â€Mongo skaliert horizontal am sinnvollsten, weil:

- Chunk-Fetches sind read-heavy
- Laststeigerungen gehen linear in die Breite
- Mongo hat eingebautes Sharding

pgvector kann replizieren, aber Sharding ist komplexer.
Redis kann replizieren oder clusterisieren â€” hier kÃ¶nnte horizontales Scaling nÃ¶tig werden, wenn Sessions & Rate-Limits stark steigen."

## 6. Welche Zugriffe sind besonders anfÃ¤llig fÃ¼r Latenzspitzen?

**Schlecht:**
â€Die Vektor-DB."

**Gut:**
â€ANN-Search kann Spitzen erzeugen."

**Exzellent:**
â€Latenzspitzen betreffen v. a.:

- Redis GET/SET (wenn die Netzwerk-Latenz steigt â†’ domino effect)
- Mongo Chunk-Fetches (bei Cold Reads â†’ E/A Peak)
- pgvector ANN-Search (bei Misses im RAM â†’ 3â€“10Ã— langsamer)

Besonders kritisch: Redis, weil der gesamte Dialog-Flow daran hÃ¤ngt."

## 7. Welche Zugriffe mÃ¼ssen p99 < 100 ms bleiben?

**Schlecht:**
â€Alle."

**Gut:**
â€Redis und Vektor-Search."

**Exzellent:**
â€FÃ¼r ein Supportsystem gelten folgende p99-Ziele:

- Redis Rate-Limit + Session Read: <5ms
- pgvector ANN: <40ms
- Chunk-Fetch (Mongo): <50ms
- Berechtigungen/Metadata (PG): <20ms

Alles zusammen muss p99 < 100ms bleiben, sonst ruckelt der Chat."

## 8. Welche Operationen sind parallelisierbar, welche NICHT?

**Schlecht:**
â€Fast alles ist parallelisierbar."

**Gut:**
â€Manche DBs lassen Anfragen parallel verarbeiten."

**Exzellent:**

**Parallelisierbar:**

- Mongo Chunk-Fetches (horizontal skalierbar)
- PG Metadata Checks (CPU-bound, gut parallelisierbar)
- Redis Reads (bei Clusterbetrieb verteilbar)

**Nicht parallelisierbar (oder nur schwer):**

- ANN-Search pro Query (kann nicht in mehrere Maschinen aufgespalten werden ohne Sharding)
- Session Updates (Redis INCR / SETEX â†’ lock-free aber SEQUENTIELL am Key)

## ğŸŸ§ TEIL 2 â€“ MusterlÃ¶sung zu den 6 Original-Fragen

## 1. Welche Datenarten existieren?

**Schlecht:**
â€Texte und Embeddings."

**Gut:**
â€Dokumenttexte, Produktdaten, Bestellungen, Chats."

**Exzellent:**
â€Wir haben:

- Dokumente (Produktbeschreibungen, Anleitungen) â†’ Mongo/JSON
- strukturiertes SQL (Kunden, Bestellungen, Zahlungen) â†’ Postgres
- Zeitreihen (LLM-Latenzen, Errors) â†’ Timescale
- AnhÃ¤nge (PDFs) â†’ Object Store
- Chat-Historien (append-only JSON) â†’ Mongo
- Vektoren (Embeddings) â†’ pgvector
- flÃ¼chtige Keys (Session, Rate-Limit, Cache) â†’ Redis"

## 2. Wo entsteht Konsistenzdruck?

**Schlecht:**
â€Bei wichtigen Daten."

**Gut:**
â€Bei Zahlungen, Kundenkonten."

**Exzellent:**
â€Konsistenz ist zwingend notwendig bei:

- Bestellungen & Zahlungen (ACID)
- ProduktverfÃ¼gbarkeit (Lagerbestand)
- Rollen/Berechtigungen (Support darf nur bestimmte Infos sehen)
- Ticket-VerknÃ¼pfungen (Wer hat welches Problem?)

Alles gehÃ¶rt in Postgres."

## 3. Wo entsteht flÃ¼chtiger State?

**Schlecht:**
â€Im Cache."

**Gut:**
â€Sessions und Cache."

**Exzellent:**
â€FlÃ¼chtige Daten:

- Rate-Limits (Redis TTL 1â€“60 Sekunden)
- Chat-Session-Context (Redis)
- Prompt-Caches (Redis SETEX)
- LLM-Error-Counters (Redis INCR)
- intermediate retrieval results (Redis 100â€“500ms TTL)"

## 4. Wo werden Vektoren benÃ¶tigt?

**Schlecht:**
â€FÃ¼r die Suche."

**Gut:**
â€FÃ¼r Ã„hnlichkeitssuche Ã¼ber Dokumente."

**Exzellent:**
â€Wir speichern Embeddings fÃ¼r:

- Produktbeschreibungen
- Anleitungs-Abschnitte
- Troubleshooting-Abschnitte
- frÃ¼here LÃ¶sungsdialoge
- FAQ-EintrÃ¤ge

Diese liegen in pgvector, damit Metadaten wie Kategorie, Hersteller, Version filterbar bleiben."

## 5. Wo braucht ihr Logs / Audit Trails?

**Schlecht:**
â€Ãœberall."

**Gut:**
â€Bei Supportaktionen und Datenzugriff."

**Exzellent:**
â€Audit Trails sind erforderlich bei:

- Zugriff auf Kundendaten (DSGVO)
- Ã„nderung von Bestellstatus
- Anzeigen von RÃ¼cksendedetails
- Systemfehlern
- LLM-Response-Latenz
- Prompt-Protokollen

Wir speichern strukturierte Logs in Timescale (Zeitreihe) und sensitive Events in PG."

## 6. Welche Teile mÃ¼ssen logisch getrennt werden?

**Schlecht:**
â€Frontend und Backend."

**Gut:**
â€Vector DB, SQL, Redis."

**Exzellent:**
â€Wir trennen logisch:

- Session Layer (Redis)
- Retrieval Layer (Vektoren) (pgvector)
- Document Store (Mongo / JSONB)
- OLTP Backend (Postgres)
- Logging / Monitoring Layer (Timescale)
- LLM Orchestration Layer
- Caching / Rate-Limit Layer (Redis)

Diese Separation verhindert:

- Datenvermischung
- Deadlocks
- Overload auf einzelnen Systemen
- inkonsistente Datenmodelle"

## ğŸŸ¥ TEIL 3 â€“ KLARE Differenzierung: p99 Latenz vs. Latenzspitzen

**Latenzspitzen:**

- UnregelmÃ¤ÃŸige AusreiÃŸer
- z. B. Cold Read, GC Pause, Docker I/O
- kÃ¶nnen Sekunden dauern
- selten, aber gefÃ¤hrlich wenn sie kritische Pfade betreffen

**p99 Latenz:**

- Die Latenz, die 99 % aller Anfragen unterschreiten
- das wichtigste SLA-Kriterium
- definiert die wahrgenommene Systemgeschwindigkeit

**Vergleich im Use-Case:**

| Bereich | Latenzspitzen | p99 Ziel |
|---------|---------------|----------|
| Redis Rate-Limit | selten: 20â€“40ms | <5ms |
| pgvector ANN | Cold RAM spike: 100â€“300ms | <40ms |
| Mongo Chunk Read | Disk Miss: 50â€“80ms | <50ms |
| PG Metadata | Lock-Wait: 20ms | <20ms |
