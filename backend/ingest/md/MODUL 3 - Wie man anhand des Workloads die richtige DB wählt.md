# MODUL 3 - Wie man anhand des Workloads die richtige DB wÃ¤hlt

## 1. Ziel dieses Moduls

Nach diesem Modul kannst du:

- eine reale DB-Auswahl wie ein Data Engineer durchfÃ¼hren,
- Workloads aus Modul 2 gezielt auf DB-Grenzen abbilden,
- Risiken erkennen, die bei falscher DB-Auswahl entstehen,
- die sechs professionellen Auswahlkriterien anwenden,
- eine saubere, nachvollziehbare Entscheidung fÃ¼r dein Capstone-Projekt dokumentieren.

Dieses Modul verknÃ¼pft:

- die Datenarten & Zugriffsszenarien aus Modul 1
- mit den Workloads & Messwerten aus Modul 2
- und fÃ¼hrt zur Datenbank-Auswahl.

## 2. Der zentrale Gedanke: DB-Auswahl ist immer Risiko-Management

Eine Datenbank ist geeignet, wenn keines der folgenden Risiken kritisch wird:

- **IntegritÃ¤tsrisiko** â€” Daten wÃ¤ren inkonsistent oder regelwidrig.
- **Workload-Risiko** â€” Die DB schafft die erwartete Last nicht.
- **Latenz-Risiko** â€” Operationen im kritischen Pfad werden zu langsam.
- **Modellierungsrisiko** â€” Dein Datenmodell passt nicht zur Engine.
- **Operations-Risiko** â€” Betrieb, Backups, Monitoring sind nicht beherrschbar.
- **Evolutions-Risiko** â€” Ã„nderungen am Produkt wÃ¤ren spÃ¤ter fast unmÃ¶glich.

Wenn du eine DB auswÃ¤hlst, entscheidest du faktisch:

â€žMit welchen Risiken kann ich leben â€” und welche darf das System nicht haben?"

Diese Denkweise ist Standard in professionellen Architekturen.

## ðŸŸ¥ 3. Die sechs Kriterien, die jede professionelle DB-Auswahl bestimmen

Wir nutzen echte Industry-Kriterien, nicht â€žBlogpost-Mythen".

### 3.1 Konsistenzanforderungen (ACID vs. eventual)

Zentrale Frage:

â€žMuss diese Operation garantiert korrekt sein?"

- Wenn ja â†’ Postgres, ACID zwingend.
- Wenn nein â†’ Mongo oder Redis mÃ¶glich.

Beispiele:

- Kundendaten (streng)
- Chat-Nachrichten (eventual)
- Rate-Limits (eventual + TTL)

### 3.2 Workload-Typ

- mixed â†’ OLTP, Kundendaten â†’ Postgres
- search-heavy â†’ Embeddings â†’ pgvector

Wenn Workload â‰  Engine-StÃ¤rken â†’ Risiko steigt.

### 3.3 Lastprofil (Load Envelope)

Entscheidend sind:

- normale Last (Requests/s)
- Peak-Last (Spikes x2/x5/x10)
- Bursts (extrem kurze Spitzen)
- Latenzbudget (z. B. < 80 ms pro RAG-Request)

Nutze wieder deine Messwerte:

- Postgres JSONB: ~400 Reads/s (realistisch)
- MongoDB: ~700+ Reads/s
- Redis: >100k Ops/s
- pgvector: 2kâ€“10k ANN/s

Beispiel:
Chunk Retrieval benÃ¶tigt 360 Reads/s beim Peak
â†’ Mongo sicher, JSONB grenzwertig.

Wichtig:
Die Zahlen hier sind Illustrationen.
FÃ¼r dein Capstone-Projekt zÃ¤hlen ausschlieÃŸlich deine eigenen Messwerte (Modul 2).

### 3.4 Kritische Query-Pfade (was beeinflusst das Antwort-Zeitbudget?)

Frage:

â€žWelche Schritte mÃ¼ssen immer schnell sein?"

Beispiel Customer-Service-RAG:

kritisch fÃ¼r User Experience:

- Redis Rate-Limit (1â€“5 ms)
- Redis Session-Lookup
- pgvector ANN-Suche (~20â€“40 ms)
- Mongo Chunk Reads (~20â€“50 ms)

NICHT kritisch:

- Logging
- Analytik
- Monitoring
- Preprocessing

â†’ Wenn eine DB im kritischen Pfad zu langsam ist, scheidet sie aus.

### 3.5 Modellierungsrisiko (passt dein Modell in diese Engine?)

Beispiele:

- Mongo wird ineffizient, wenn du viele Teil-Updates brauchst
- Redis kann keine komplexen Queries
- Postgres JSONB ist schlecht fÃ¼r riesige Dokumente

### 3.6 Operability (Betreibbarkeit)

Professionelle Systeme gehen kaputt, wenn Operability ignoriert wird.

Fragen:

- Kann das Team Backups fahren?
- Sind Upgrades einfach?
- Wie schwer ist Monitoring?
- Ist HochverfÃ¼gbarkeit trivial oder komplex?
- Ist Persistence (Redis!) zuverlÃ¤ssig konfigurierbar?

Beispiel:
Redis ist ultraschnell, aber nur sicher mit RDB/AOF-Konfiguration und Replika-Setup.

## ðŸŸ¥ 4. Der professionelle Entscheidungsprozess (5 Schritte)

Die Industrie nutzt genau diesen Ablauf:

### Schritt 1 â€” Datenobjekte bestimmen (Modul 1)

z. B.:
Chunk, Embedding, Kundendatensatz, Chatnachricht, Session-Item

### Schritt 2 â€” Zugriffsszenarien bestimmen (Modul 1)

z. B.:
6 Chunk-Reads, Append-Write, Profil-Update, Session-Lookup

### Schritt 3 â€” Workloads quantifizieren (Modul 2)

Nutze deine Messwerte.

Beispiel:
40 Requests/s Ã— 6 Chunk-Reads = 240 Chunk Reads/s
â†’ Mongo sicher (gemessen), JSONB grenzwertig (gemessen)

### Schritt 4 â€” die sechs Kriterien anwenden (dieses Modul)

Beispiel:

- Postgres â†’ ACID gut, aber JSONB bei 240 Reads/s knapp
- Mongo â†’ read-heavy stark, eventual consistency ausreichend
- pgvector â†’ ANN performant
- Redis â†’ Sessions extrem schnell

### Schritt 5 â€” Entscheidung dokumentieren (Capstone)

Eine vollstÃ¤ndige Entscheidung enthÃ¤lt:

- die Alternativen
- die Workloads
- die Risiken
- die begrÃ¼ndete Auswahl
- die AusschlussgrÃ¼nde

Genau das wird bewertet.

## ðŸŸ¥ 5. Beispiel: Auswahl fÃ¼r ein Customer-Service-RAG

### Objekt 1 â€” Kundendaten

- Konsistenz: Hoch
- Workload: mixed
- Pfad: kritisch
- Modell: relational

â†’ Postgres

### Objekt 2 â€” Chunks

- Konsistenz: gering
- Workload: read-heavy
- Pfad: kritisch
- Modell: groÃŸes semistrukturiertes Dokument

â†’ MongoDB

### Objekt 3 â€” Embeddings

- Konsistenz: gering
- Workload: search-heavy
- Pfad: kritisch
- Modell: Vektoren

â†’ pgvector

### Objekt 4 â€” Session / Rate-Limit

- Konsistenz: gering
- Workload: write-heavy, tiny ops
- Pfad: kritisch
- Modell: Key-Value

â†’ Redis

## ðŸŸ¥ 6. Capstone-Verpflichtungen

In deiner Ausarbeitung musst du:

- âœ” Datenobjekte definieren
- âœ” Zugriffsszenarien bestimmen
- âœ” Workloads quantifizieren
- âœ” deine Messwerte anwenden
- âœ” die sechs Kriterien nutzen
- âœ” Alternativen ausschlieÃŸen
- âœ” die finale Entscheidung begrÃ¼nden

Ohne diese Struktur ist die Abgabe unvollstÃ¤ndig.

## ðŸŸ¥ 7. Aufgaben (Mini, 10â€“20 Minuten)

### Aufgabe 1 â€” Engine auswÃ¤hlen

Gegeben:

- 240 Reads/s (Peak)
- Chunks Ã  3â€“5 KB
- Latenzbudget: <80 ms

Welche Engine?

**LÃ¶sung:** MongoDB

**BegrÃ¼ndung:** read-heavy, Dokumentstruktur, hohe DurchsatzfÃ¤higkeit

(Hinweis: Nutze spÃ¤ter deine eigenen Messwerte!)

### Aufgabe 2 â€” Embedding-Engine

Gegeben:

- 4 000 ANN-Queries/s
- Filter nach Produktfamilie
- kritische Latenz

Welche Engine?

**LÃ¶sung:** pgvector

## ðŸŸ¥ 8. HÃ¤ufige Fehlentscheidungen

- â€žPostgres ist immer sicher."
- â€žMongo ist flexibler."
- â€žRedis ist schnell, also ideal."
- â€žIch benchmarke ein paar Inserts, das reicht."
- â€žWir nehmen die DB, die wir kennen."

Alle fÃ¼nf ignorieren Workloads, Risiken und Pfade.

## ðŸŸ¥ 9. LLM-Assist (optional)

Beispiel-Prompts:

- â€žWelche Risiken Ã¼bersehe ich bei dieser DB-Auswahl?"
- â€žWelche kritischen Query-Pfade habe ich nicht berÃ¼cksichtigt?"
- â€žWelche Konsistenzanforderungen gelten fÃ¼r mein Datenobjekt?"

LLMs ersetzen nicht die Messungen â€”
sie helfen dir, bessere Fragen zu stellen.
