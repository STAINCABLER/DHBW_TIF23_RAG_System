In Modul 4 hast du gelernt, wie man Query Paths identifiziert und bewertet.
Du wei√üt jetzt:

welche Schritte eine Anfrage im System durchl√§uft,

welche davon kritisch sind (‚Üí beeinflussen die Antwortzeit),

welche davon nicht kritisch sind (‚Üí d√ºrfen langsam sein),

welche Datenbanken in diesen Pfaden liegen,

welches Latenzbudget diese Pfade haben.

In Modul 5 geht es darum, aus diesen Query Paths das tats√§chliche Datenmodell zu bauen.

Du lernst:

wie man aus einem Query Path ein konkretes Dokument- oder Tabellenmodell ableitet,

wann man Daten zusammen in ein Dokument packt (embed),

wann man sie lieber trennt (reference),

wie man Roundtrips vermeidet,

wie man Dokumentgr√∂√üen w√§hlt,

und wie man Datenmodelle so strukturiert, dass sie den kritischen Pfad optimieren.

Modul 5 beantwortet also die Frage:

üëâ ‚ÄûWie muss ich die Daten physisch strukturieren, damit meine wichtigsten Queries schnell sind?‚Äú
Zusammengefasst:
Modul 4 = verstehen, welche Pfade kritisch sind
(Analyse der Zugriffswege und Latenzen)

Modul 5 = das Modell so designen, dass diese Pfade optimal laufen
(Access-Path-basierte Datenmodellierung)

Beide Module geh√∂ren zusammen.

Modul 4 zeigt dir, was das System tun muss.
Modul 5 zeigt dir, wie du deine Daten daf√ºr strukturierst.


1. Ziel des Moduls
Nach diesem Modul kannst du:

erkennen, warum Datenmodelle aus Queries entstehen, nicht aus ‚ÄûFeldern‚Äú,

Access-Path-basierte Modellierung anwenden,

entscheiden, wann ein Dokument gro√ü/klein sein sollte,

entscheiden, wann man Daten embedden und wann referenzieren sollte,

Roundtrips vermeiden,

ein dokumentenorientiertes Datenmodell f√ºr deinen Capstone erstellen.

Dieses Modul ist die Basis f√ºr alles, was danach kommt: Chunking, Embeddings, Metadaten, Retrieval.

2. Der wichtigste Paradigmenwechsel
Falsch (klassisch, SQL-Denke):

‚ÄûIch baue erst Tabellen, dann schreibe ich Queries.‚Äú

Richtig (professionelles Data Engineering):

‚ÄûIch definiere zuerst die Queries, dann baue ich das Datenmodell.‚Äú

Warum?

Weil Latenz, Kosten und Skalierung immer aus den Query Paths kommen ‚Äî nie aus der ‚ÄûDatenstruktur an sich‚Äú.

3. Kernprinzip: Access Paths bestimmen das Modell
Ein Access Path ist:

welche Daten,

in welcher Reihenfolge,

aus welchen Objekten,

mit welcher Latenz,

f√ºr welche Operation

gelesen werden m√ºssen.

Dein Modell muss genau diese Paths optimieren ‚Äî nicht mehr, nicht weniger.

Merksatz:

Ein gutes Dokumentenmodell ist ein Replikat deiner Query Paths.

4. Drei Modellierungsentscheidungen, die alles bestimmen
Wenn du ein NoSQL-/Dokumentenmodell baust, entscheidet genau Folgendes:

4.1 EMBED vs REFERENCE
Embed, wenn:

du immer alles gemeinsam liest

die Daten klein sind

du Roundtrips vermeiden willst

Konsistenz nicht kritisch ist

Reference, wenn:

separate Updates n√∂tig sind

Daten gro√ü sind

Objekt eigenst√§ndige Lebenszyklen hat

Konsistenz wichtig ist

4.2 Big Documents vs Small Documents
Gro√üe Dokumente, wenn:

du fast immer das ganze Ding brauchst

wenig Update-Druck besteht

du Latenz minimieren willst

Kleine Dokumente, wenn:

du nur Teilmengen liest

das Objekt h√§ufig aktualisiert wird

du breitere Slices brauchst (z. B. nach Kategorie)

4.3 Precompute vs Compute-on-Read
Precompute, wenn:

Query im kritischen Pfad

Sort/Filter teuer

viele Reads / wenige Writes

Compute-on-Read, wenn:

Daten winzig

wenige Aufrufe

Berechnung trivial




Fallstudie ‚Äì Median-Lieferzeit 
Ziel: An diesem Beispiel siehst Du, wie man komplett aus dem Access Path und den drei Modellierungsentscheidungen das richtige Datenmodell ableitet.

1. Access Path (Schritt f√ºr Schritt)
Fragestellung:
‚ÄûWie hoch ist die mediane Lieferzeit f√ºr eine Produktkategorie im letzten 30-Tage-Fenster?‚Äú

Access Path:

Finde alle Lieferereignisse der letzten 30 Tage.

Berechne die Lieferdauer je Ereignis.

Sortiere alle Lieferdauern.

Nimm den mittleren Wert ‚Üí Median.

Der Median kann nur berechnet werden, wenn alle Einzelwerte vorhanden sind.

2. Die drei Modellierungsentscheidungen (wie in Modul 5)
4.1 EMBED vs. REFERENCE
‚ùå EMBED (falsch)
Beispiel f√ºr eine schlechte Modellierung:

{
  "product_id": 123,
  "category": "Coffee Machines",
  "deliveries": [
    { "delivery_id": 1, "shipped_at": "...", "delivered_at": "..." },
    { "delivery_id": 2, "shipped_at": "...", "delivered_at": "..." }
    // viele weitere
  ]
}
Probleme:

sehr gro√üe Dokumente

schwer indexierbar

Sortierung in Arrays teuer

das ganze Dokument muss f√ºr jede Berechnung geladen werden

‚úîÔ∏è REFERENCE (richtig)
Eine Lieferung = ein einzelnes Dokument/Objekt.

{
  "delivery_id": 924881,
  "product_id": 123,
  "category": "Coffee Machines",
  "shipped_at": "2025-03-01T10:00:00Z",
  "delivered_at": "2025-03-05T09:12:00Z",
  "delivery_days": 3.96
}
Vorteile:

sauber filterbar

gut indexierbar

ideale Basis f√ºr Sortierung

kein Dokumentwachstum

Ergebnis: F√ºr Median-Berechnung ist REFERENCE zwingend.

4.2 Big Document vs. Small Document
‚ùå Big Document (falsch)
Beispiel:

{
  "category": "Coffee Machines",
  "delivery_stats": {
    "durations_last_30_days": [2.1, 4.0, 3.9, 6.2, ...]
  }
}
Probleme:

arrays werden riesig

Sortierung findet im Dokument statt

vollst√§ndig laden ‚Üí hohe Latenz

Updates blockieren sich gegenseitig

‚úîÔ∏è Small Document (richtig)
Small Documents:

flache Struktur

1 Ereignis = 1 Dokument

sehr gut indexierbar

kein wachsendes ‚ÄúMega-Dokument‚Äù

Ergebnis: Median-Berechnung funktioniert nur mit vielen kleinen Dokumenten.

4.3 Precompute vs. Compute-on-Read
‚ùå Compute-on-Read (falsch)
Jede Anfrage m√ºsste:

alle Lieferungen laden

sortieren

Median berechnen

‚Üí sehr teuer
‚Üí langsam
‚Üí hohe Serverlast

‚úîÔ∏è Precompute (richtig)
Median wird zyklisch im Hintergrund berechnet.
Abfrage braucht nur noch einen einzigen Wert.

Vorteile:

schnelle Antwortzeiten

kritischer Pfad minimal

gut skalierbar

Ergebnis: Median muss precomputed werden.

3. Das daraus abgeleitete Datenmodell
3.1 Tabelle f√ºr Lieferereignisse
CREATE TABLE deliveries (
  delivery_id     bigserial PRIMARY KEY,
  product_id      bigint NOT NULL,
  category        text   NOT NULL,
  shipped_at      timestamptz NOT NULL,
  delivered_at    timestamptz NOT NULL,
  delivery_days   numeric GENERATED ALWAYS AS
       ((EXTRACT(EPOCH FROM delivered_at - shipped_at)/86400)) STORED
);

CREATE INDEX idx_deliveries_category_time
  ON deliveries (category, shipped_at);
3.2 Materialized View f√ºr den Median
CREATE MATERIALIZED VIEW mv_median_delivery AS
SELECT category,
       percentile_cont(0.5)
         WITHIN GROUP (ORDER BY delivery_days) AS median_delivery_days
FROM deliveries
WHERE shipped_at > now() - interval '30 days'
GROUP BY category;
4. Kritischer Pfad (Modul 4 Bezug)
Query Path:

SELECT median_delivery_days
FROM mv_median_delivery
WHERE category = 'Coffee Machines';
Warum dieser Pfad kritisch ist:

wird h√§ufig aufgerufen

muss schnell sein

Sortierung darf nicht im Pfad liegen

kleiner Lookup statt gro√üer Array-Operation

Datenmodell unterst√ºtzt diesen Pfad durch:

Small Documents

Reference-Modell

Index auf Zeitfenster

Precompute




Latenz in diesem Szenario
Die drei Modellierungsentscheidungen reduzieren die Latenz im kritischen Pfad:

Modellierungsform	Latenz pro Anfrage	Problem
Compute-on-Read (Sortierung)	80‚Äì300 ms	zu langsam f√ºr Dashboards
Big Document (500 KB ‚Äì 2 MB)	20‚Äì50 ms	Transfer + Parsing zu teuer
Small Documents + Index	5‚Äì10 ms	optimal
Precompute (Materialized View)	3‚Äì5 ms	perfekter kritischer Pfad



5. Check-Dein-Verst√§ndnis
Kannst Du f√ºr dieses Beispiel:

EMBED vs. REFERENCE korrekt begr√ºnden?

Big Document vs. Small Document unterscheiden?

Precompute vs. Compute-on-Read erkl√§ren?

zeigen, wie genau der Access Path das Modell bestimmt?




6. Access-Path-Mapping f√ºr dein Capstone
F√ºr jedes deiner Objekte musst du beantworten:

6.1 Welche Queries lese ich IMMER?
Wenn 90 % der Queries dieselben Felder laden ‚Üí EMBED.

6.2 Welche Queries liegen IM CRITICAL PATH?
Diese m√ºssen die wenigsten Roundtrips haben.

6.3 Welche Daten wachsen schnell?
Gro√üe Arrays ‚Üí manchmal splitten.

6.4 Welche Daten werden h√§ufig aktualisiert?
Gro√üe Dokumente mit Updates ‚Üí schlecht.

6.5 Welche Daten passen gut in ein Dokument?
Z. B. alle Chunk-Metadaten.

6.6 Welche m√ºssen separat versioniert werden?
z. B. Kundenprofile.

7. H√§ufige Modellierungsfehler (bewertungsrelevant)
Zu gro√üe Dokumente: 300 kB PDFs in Mongo speichern

Zu kleine Dokumente: 1 Satz pro Dokument

Metadaten vergessen (section_title, position)

embedding ins Chunk speichern ‚Üí unn√∂tig gro√ü

Chat als 1 Dokument pro Nachricht ‚Üí 1000 Roundtrips

Mongo nutzen f√ºr ACID-Operationen

Referenzen nutzen, obwohl kein Update n√∂tig ist

8. Bezug zum Capstone (explizit pr√ºfrelevant)
In deiner Ausarbeitung muss stehen:

Welche Access Paths dein System hat

Wie du daraus konkret dein Datenmodell abgeleitet hast (und wie es die Latenzen adressiert)

Warum EMBED/REFERENCE gew√§hlt wurde

Warum deine Dokumentgr√∂√üe sinnvoll ist

Wie dein Modell kritische Pfade minimiert 

Welche Risiken du bewusst ausgeschlossen hast

Wenn du das nicht explizit dokumentierst, gilt das Modell als nicht begr√ºndet.