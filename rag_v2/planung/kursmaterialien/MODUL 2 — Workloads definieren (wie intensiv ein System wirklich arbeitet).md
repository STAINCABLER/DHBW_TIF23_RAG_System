1. Ziel des Moduls
Nach diesem Modul kannst du:

aus Zugriffsszenarien echte Workloads ableiten,

verstehen, warum Workloads ohne Zahlen wertlos sind,

Anforderungen exakt formulieren (Reads/s, Writes/s, Latenzbudgets),

Messwerte sammeln, die spÃ¤ter fÃ¼r die DB-Auswahl entscheidend sind,

kritische Operationen identifizieren.

Dieses Modul ist die BrÃ¼cke zwischen
â€Wie nutzen wir die Daten?â€œ (Modul 1)
und
â€Welche Datenbank kann das leisten?â€œ (Modul 3).

2. Warum Workloads notwendig sind
Viele glauben, man kÃ¶nne Datenbanken so auswÃ¤hlen:

â€Dokumente â†’ Mongo.â€œ
â€Vektoren â†’ Vektor-DB.â€œ
â€Key-Value â†’ Redis.â€œ

Das ist falsch.

Warum?

Weil Datenbanken nicht wegen ihrer Typen, sondern wegen ihrer Grenzen scheitern:

zu viele Writes

zu groÃŸe Peaks

zu hohe ParallelitÃ¤t

zu niedrige Toleranz fÃ¼r Latenz

zu starke Anforderungen an Konsistenz

Um diese Grenzen zu verstehen, brauchst du:

â†’ Workloads mit echten Zahlen.
Begriffe wie
â€hochâ€œ, â€niedrigâ€œ, â€vielâ€œ, â€seltenâ€œ, â€oftâ€œ
sind keine Workloads.

ğŸŸ¦ 3. Die 4 Dimensionen eines Workloads
Ein Workload beschreibt wie intensiv ein Zugriffsszenario im System ausgefÃ¼hrt wird.

3.1 HÃ¤ufigkeit
Wie oft passiert die Operation?

Beispiele:
â€“ 12 Reads/s
â€“ 500 Inserts/min
â€“ 2 Updates/Tag

3.2 ParallelitÃ¤t
Wie viele Nutzer/Requests gleichzeitig?

Beispiele:
â€“ 5 aktive Agents
â€“ 40 parallele Anfragen
â€“ 200 gleichzeitige ANN-Suchen

3.3 Ã„nderungsintensitÃ¤t
Wie stark verÃ¤ndern sich die Daten?

Beispiele:
â€“ nur lesen
â€“ hÃ¤ufiges Ãœberschreiben
â€“ Append-only
â€“ Bulk-Ingest

3.4 KritikalitÃ¤t / Fehlertoleranz
Was passiert, wenn die Operation:

200 ms dauert?

3 Sekunden dauert?

verloren geht?

verdoppelt wird?

verspÃ¤tet eintrifft?

Die Antwort bestimmt spÃ¤ter die Wahl zwischen
â€“ strenger Konsistenz
â€“ eventual consistency
â€“ asynchronem Logging
â€“ Caching
â€“ Queueing

ğŸŸ¥ 4. Aus Zugriffsszenarien werden Workloads
Ein Zugriffsszenario aus Modul 1:

â€Dokument + read-heavy â†’ Chunk Retrievalâ€œ

wird erst durch Zahlen zu einem Workload:

â€360 Chunk Reads/s im Peak,
Ziel-Latenz < 80 ms,
keine Updates.â€œ

Ohne diese Daten kannst du keine Datenbank sinnvoll auswÃ¤hlen.

ğŸŸ© 5. Der Mini-Use-Case (zum Messen & Ãœben)
Bevor wir zum groÃŸen RAG-Szenario gehen, arbeitest du zuerst mit einem einfachen, kleinen Use-Case:

Drei Objekte:
Produktbeschreibung (~3 KB)

Kundenprofil (~300 Bytes)

Chatnachricht (~150 Bytes)

Drei Operationen:
Lesen

Schreiben

Append (fÃ¼r Chat)

Ein Mess-Setup:
Postgres

MongoDB

Mit diesen Systemen kannst du alles messen, was du brauchst.

ğŸŸ§ 6. Was du messen musst (Pflicht!)
Um Workloads beurteilen zu kÃ¶nnen, misst du:

Operation	MongoDB	Postgres
Read (einzeln)	X ms	Y ms
Write (einzeln)	X ms	Y ms
Update	X ms	Y ms
Append	X ms	Y ms
Bulk Read (100)	X ms	Y ms
Bulk Write (100)	X ms	Y ms
Diese 6 Messwerte ermÃ¶glichen dir spÃ¤ter zu beurteilen:

Schafft Mongo 300 Reads/s?

Schafft Postgres 40 Updates/s?

Ist Append in Mongo schnell genug?

Ist Bulk-Ingest in Postgres zu langsam?

Die Messwerte sind nicht optional.
Sie sind die Grundlage fÃ¼r jede Entscheidung im Capstone-Projekt.

ğŸŸ¦ 7. Formel: Workload = erwartete Last Ã— gemessene Leistung
Beispiele:

Wenn du misst:
MongoDB kann 750 Reads/s

Und der Use-Case braucht:
360 Reads/s

â†’ passt.

Wenn du misst:
Postgres schafft 15 Writes/s

Aber dein Use-Case braucht:
40 Writes/s

â†’ passt nicht â†’ Modell oder Technologie Ã¤ndern (Modul 4).

Warum Workloads auch Ã¼ber â€œCloud vs. Docker vs. Nativeâ€ entscheiden
Workloads bestimmen nicht nur welche Datenbank geeignet ist,
sondern auch wie du sie betreiben kannst.

Viele Studierende (und viele Unternehmen) machen am Anfang den Fehler, einfach anzunehmen:

â€Cloud ist immer besser.â€œ

â€Docker reicht fÃ¼r alles.â€œ

â€Lokal testen, in der Cloud betreiben.â€œ

Das ist nicht professionell und fÃ¼hrt oft zu FehleinschÃ¤tzungen.

Hosting hÃ¤ngt direkt vom Workload ab:
1. Wenn eine Datenbank fÃ¼r deinen Workload zu langsam ist â†’ hilft auch Cloud nicht.
Cloud beschleunigt keine Engine, die unter deinem Workload kollabiert.
â†’ Erst messen, DANN Ã¼ber Hosting nachdenken.

2. Wenn ein Workload viele kleine Latenzen hat (<5 ms), kann Cloud zu langsam sein.
Beispiel: Redis-Sessions oder Rate-Limits
â†’ kleine LatenzsprÃ¼nge von 2â€“5 ms ruinieren den kritischen Pfad.

3. Wenn ein Workload sehr I/O-lastig ist, kann Docker lokale Performance massiv reduzieren.
â†’ Bulk-Writes, ANN-Builds, JSONB-Indexing
â†’ Container-Filesysteme verhalten sich anders als native Installationen.

4. Wenn ein Workload Burst-Spitzen hat (x5/x10), sind Cloud-Preise plÃ¶tzlich ein Problem.
â†’ Autoscaling klingt gut, wird aber teuer.

5. Wenn dein Workload klein ist, ist Cloud hÃ¤ufig Overkill.
â†’ Lokale Postgres/Redis/Mongo auf einem einzelnen Host reicht vÃ¶llig.

Kurz gesagt:
Workloads verhindern Hosting-Schema-F.

Workloads zwingen dich, diese Fragen zu beantworten:

â€Kann ich diesen kritischen Pfad in der Cloud-Latenz Ã¼berhaupt erreichen?â€œ

â€Welche Engine verhÃ¤lt sich in Docker realitÃ¤tsnah â€“ welche nicht?â€œ

â€Kann ich mir Burst-Kosten fÃ¼r ANN-Suche leisten?â€œ

â€Reicht lokale Performance aus? Muss ich sharden?â€œ

Erst wenn du den Workload kennst, kannst du entscheiden:

lokal

Docker

Cloud managed

hybrid

Ohne Workload â†’ Hosting ist reine Spekulation.
Mit Workload â†’ Hosting ist eine technisch begrÃ¼ndete Entscheidung.


ğŸŸ¥ 8. Ãœbergang zum groÃŸen RAG-Use-Case
Jetzt kommen wir zurÃ¼ck zu unserem Customer-Service-RAG:

Du kennst aus Modul 1 die Szenarien:

Chunk Retrieval

Chat Append

Kundenprofil Update

Session Zugriff

ANN Suche

Logging

Typische Last:

12 RAG-Requests/s normal

40 RAG-Requests/s peak

Wenn jeder Request
â€“ 6 Chunks liest
â€“ 1 Kundenprofil liest/Ã¤ndert
â€“ 1 Nachricht anhÃ¤ngt
â€“ 1 Embedding sucht

Dann ergibt sich z. B.:

Chunk Reads:
40 Requests/s Ã— 6 Chunks = 240 Reads/s

Embedding ANN:
40 ANN-Abfragen/s

Chat-Appends:
40 Writes/s

Session State (KV):
80â€“120 kleine Reads/Writes/s

Ohne Workloads kannst du nicht beurteilen:

ob Mongo 240 Reads/s schafft,

ob Postgres Updates im Peak packt,

ob Redis nÃ¶tig ist,

ob ANN-Suche ausgelagert werden muss.

Damit Modul 3 funktionieren kann, benÃ¶tigst du diese Zahlen.

ğŸŸ¥ 9. Capstone-Relevanz 
In deiner Abgabe musst du:

âœ” fÃ¼r jedes Objekt ein Zugriffsszenario aus Modul 1 haben
âœ” aus jedem Szenario einen Workload mit konkreten Zahlen ableiten
âœ” begrÃ¼nden, welche Messwerte du brauchst
âœ” spÃ¤ter (in Modul 3) eine DB-Auswahl treffen
âœ” zeigen, dass deine Entscheidung auf Zahlen und nicht auf BauchgefÃ¼hl basiert

Wenn du keine Zahlen angibst, kannst du keine DB begrÃ¼nden.

ğŸŸ¦ 10. Mini-Aufgaben 
A) Welche Messungen fehlen?
Gegeben:
â€Unser System erwartet 150 Reads/s und 30 Writes/s.â€œ

Frage:
Welche Messungen brauchst du MINDESTENS, um zu entscheiden,
ob Postgres oder MongoDB geeignet ist?

B) Welche Aussagen sind brauchbar â€” welche wertlos?
â€Mongo ist schneller als Postgres.â€œ

â€Mongo braucht 2,1 ms fÃ¼r einen Read, Postgres 4,8 ms.â€œ

â€Unsere Chats bestehen aus AnhÃ¤ngen, nicht Updates.â€œ

â€Unser Use-Case hat viele Reads.â€œ

C) Baue deinen eigenen Workload
Nimm ein Objekt aus deinem Capstone (z. B. â€Themenabschnittâ€œ oder â€Beispielantwortâ€œ).

Bestimme:

Datenart

Zugriffsszenario

erwartete HÃ¤ufigkeit

erwartete ParallelitÃ¤t

erwartete Ã„nderungsintensitÃ¤t

KritikalitÃ¤t

Welche Messwerte du brauchst

ğŸŸ§ 11. MusterlÃ¶sungen 
A) Messungen, die fehlen
Read-Latenz (einzeln & bulk)

Write-Latenz (einzeln & bulk)

Update-Latenz

Append-Latenz

Durchsatz beider Systeme

Optionale p95 Latenzen

Typische Fehler:

Nur Reads gemessen

Bulk nicht gemessen

Nur eine DB getestet

Debug-Modus benutzt

Laptop im Energiesparmodus

B) Bewertung der Aussagen
Aussage	Bewertung	Warum
1	wertlos	ohne Zahlen nutzlos
2	nÃ¼tzlich	direkt vergleichbar
3	nÃ¼tzlich	beeinflusst Modell & Last
4	wertlos	keine Zahl â†’ kein Workload
C) Beispiel-Workload
Objekt: â€Themenabschnittâ€œ
Datenart: Dokument
Zugriffsszenario: viele Reads, wenige Updates
Messwerte benÃ¶tigt:

Read-Lat

Bulk-Reads

Write-Lat
DB-Kandidaten: Dokumentenspeicher

ğŸŸ¦ 12. Check: Habe ich Modul 2 verstanden?
Kannst du:

fÃ¼r jedes Objekt einen Workload definieren?

Zahlen angeben statt WÃ¶rter?

die 4 Dimensionen klar anwenden?

sagen, welche Messwerte du brauchst?

erklÃ¤ren, warum Workloads die Vorstufe zur DB-Auswahl sind?

Wenn ja â†’ weiter zu Modul 3: Datenbank-Auswahl auf Profi-Niveau.